{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkBb2lhTScDLHExSl6OII7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnnaDS/ChatBots/blob/main/ChatBot_with_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create ChatBot with RAG from Youtube video or Pdf document"
      ],
      "metadata": {
        "id": "hu6848tBu4RH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing required packages"
      ],
      "metadata": {
        "id": "uyFdxCqiCg8v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uQkFTukiCPt9",
        "outputId": "6aa1af6f-05be-44dd-96de-98b6987e8818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.0-py3-none-any.whl (32 kB)\n",
            "Collecting langchainhub\n",
            "  Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidocr-onnxruntime\n",
            "  Downloading rapidocr_onnxruntime-1.3.15-py3-none-any.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit\n",
            "  Downloading streamlit-1.32.2-py2.py3-none-any.whl (8.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unstructured\n",
            "  Downloading unstructured-0.12.6-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pikepdf\n",
            "  Downloading pikepdf-8.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow_heif\n",
            "  Downloading pillow_heif-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.0.55-py3-none-any.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.33 (from langchain_community)\n",
            "  Downloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n",
            "  Downloading langsmith-0.1.31-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Collecting openai<2.0.0,>=1.10.0 (from langchain-openai)\n",
            "  Downloading openai-1.14.2-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.31.0.20240311-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.1.1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.4)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.10.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.3.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting pyclipper>=1.2.0 (from rapidocr-onnxruntime)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.5.1.48 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (4.8.0.76)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (1.16.0)\n",
            "Requirement already satisfied: Shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (2.0.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (9.4.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Collecting packaging<24,>=16.8 (from streamlit)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff==2.2.1 (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: beautifulsoup4==4.12.3 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
            "Requirement already satisfied: certifi==2024.2.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2024.2.2)\n",
            "Requirement already satisfied: chardet==5.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.3.2)\n",
            "Collecting dataclasses-json-speakeasy==0.5.11 (from unstructured)\n",
            "  Downloading dataclasses_json_speakeasy-0.5.11-py3-none-any.whl (28 kB)\n",
            "Collecting emoji==2.10.1 (from unstructured)\n",
            "  Downloading emoji-2.10.1-py2.py3-none-any.whl (421 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filetype==1.2.0 (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: idna==3.6 in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.6)\n",
            "Requirement already satisfied: joblib==1.3.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.3.2)\n",
            "Collecting jsonpath-python==1.0.6 (from unstructured)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Collecting langdetect==1.0.9 (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lxml==5.1.0 (from unstructured)\n",
            "  Downloading lxml-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow==3.20.2 (from unstructured)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions==1.0.0 (from unstructured)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Collecting numpy<2,>=1 (from langchain_community)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.8.2)\n",
            "Collecting python-iso639==2024.2.7 (from unstructured)\n",
            "  Downloading python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic==0.4.27 (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Collecting rapidfuzz==3.6.1 (from unstructured)\n",
            "  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve==2.5 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.5)\n",
            "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Collecting typing-extensions>=4.5.0 (from chromadb)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting typing-inspect==0.9.0 (from unstructured)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting unstructured-client==0.18.0 (from unstructured)\n",
            "  Downloading unstructured_client-0.18.0-py3-none-any.whl (21 kB)\n",
            "Collecting urllib3==1.26.18 (from unstructured)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrapt==1.16.0 (from unstructured)\n",
            "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (42.0.5)\n",
            "Collecting Pillow (from rapidocr-onnxruntime)\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Deprecated (from pikepdf)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain_community) (3.7.1)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
            "Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n",
            "Collecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
            "INFO: pip is looking at multiple versions of types-requests to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.31.0.20240310-py3-none-any.whl (14 kB)\n",
            "  Downloading types_requests-2.31.0.20240218-py3-none-any.whl (14 kB)\n",
            "  Downloading types_requests-2.31.0.20240125-py3-none-any.whl (14 kB)\n",
            "  Downloading types_requests-2.31.0.20240106-py3-none-any.whl (14 kB)\n",
            "  Downloading types_requests-2.31.0.20231231-py3-none-any.whl (14 kB)\n",
            "  Downloading types_requests-2.31.0.10-py3-none-any.whl (14 kB)\n",
            "  Downloading types_requests-2.31.0.9-py3-none-any.whl (14 kB)\n",
            "INFO: pip is looking at multiple versions of types-requests to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading types_requests-2.31.0.8-py3-none-any.whl (14 kB)\n",
            "  Downloading types_requests-2.31.0.7-py3-none-any.whl (14 kB)\n",
            "  Downloading types_requests-2.31.0.6-py3-none-any.whl (14 kB)\n",
            "Collecting types-urllib3 (from types-requests<3.0.0.0,>=2.31.0.2->langchainhub)\n",
            "  Downloading types_urllib3-1.26.25.14-py3-none-any.whl (15 kB)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain_community) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.18.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
            "Building wheels for collected packages: langdetect, pypika\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=e4efd49c0c455dc65b73b798730abb39fdac5179945c97194f0a16c5ddab4115\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=923c25640dbd0c0c57f3f8aa64f5e17508cdd9a30a9b0281c85864e8018ba644\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built langdetect pypika\n",
            "Installing collected packages: types-urllib3, pypika, pyclipper, monotonic, mmh3, filetype, wrapt, websockets, watchdog, uvloop, urllib3, typing-extensions, types-requests, smmap, rapidfuzz, python-magic, python-iso639, python-dotenv, pypdf, pulsar-client, Pillow, packaging, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, numpy, mypy-extensions, lxml, langdetect, jsonpointer, jsonpath-python, importlib-metadata, humanfriendly, httptools, h11, emoji, bcrypt, backoff, watchfiles, uvicorn, typing-inspect, starlette, pydeck, pillow_heif, pdf2image, opentelemetry-exporter-otlp-proto-common, marshmallow, jsonpatch, httpcore, gitdb, Deprecated, coloredlogs, chroma-hnswlib, asgiref, tiktoken, posthog, pikepdf, pdfminer.six, opentelemetry-api, onnxruntime, langchainhub, httpx, gitpython, dataclasses-json-speakeasy, dataclasses-json, unstructured-client, rapidocr-onnxruntime, opentelemetry-sdk, opentelemetry-instrumentation, openai, langsmith, kubernetes, fastapi, unstructured, streamlit, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langchain-core, opentelemetry-instrumentation-fastapi, langchain-text-splitters, langchain-openai, langchain_community, langchain, chromadb, langchain_experimental\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.10.0\n",
            "    Uninstalling typing_extensions-4.10.0:\n",
            "      Successfully uninstalled typing_extensions-4.10.0\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.9.4\n",
            "    Uninstalling lxml-4.9.4:\n",
            "      Successfully uninstalled lxml-4.9.4\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 7.0.2\n",
            "    Uninstalling importlib_metadata-7.0.2:\n",
            "      Successfully uninstalled importlib_metadata-7.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.2.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.2.0 which is incompatible.\n",
            "tensorflow 2.15.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.16.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Deprecated-1.2.14 Pillow-10.2.0 asgiref-3.8.0 backoff-2.2.1 bcrypt-4.1.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 dataclasses-json-0.6.4 dataclasses-json-speakeasy-0.5.11 emoji-2.10.1 fastapi-0.110.0 filetype-1.2.0 gitdb-4.0.11 gitpython-3.1.42 h11-0.14.0 httpcore-1.0.4 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 importlib-metadata-6.11.0 jsonpatch-1.33 jsonpath-python-1.0.6 jsonpointer-2.4 kubernetes-29.0.0 langchain-0.1.13 langchain-core-0.1.33 langchain-openai-0.1.0 langchain-text-splitters-0.0.1 langchain_community-0.0.29 langchain_experimental-0.0.55 langchainhub-0.1.15 langdetect-1.0.9 langsmith-0.1.31 lxml-5.1.0 marshmallow-3.20.2 mmh3-4.1.0 monotonic-1.6 mypy-extensions-1.0.0 numpy-1.26.4 onnxruntime-1.17.1 openai-1.14.2 opentelemetry-api-1.23.0 opentelemetry-exporter-otlp-proto-common-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.23.0 opentelemetry-instrumentation-0.44b0 opentelemetry-instrumentation-asgi-0.44b0 opentelemetry-instrumentation-fastapi-0.44b0 opentelemetry-proto-1.23.0 opentelemetry-sdk-1.23.0 opentelemetry-semantic-conventions-0.44b0 opentelemetry-util-http-0.44b0 orjson-3.9.15 overrides-7.7.0 packaging-23.2 pdf2image-1.17.0 pdfminer.six-20231228 pikepdf-8.13.0 pillow_heif-0.15.0 posthog-3.5.0 pulsar-client-3.4.0 pyclipper-1.3.0.post5 pydeck-0.8.1b0 pypdf-4.1.0 pypika-0.48.9 python-dotenv-1.0.1 python-iso639-2024.2.7 python-magic-0.4.27 rapidfuzz-3.6.1 rapidocr-onnxruntime-1.3.15 smmap-5.0.1 starlette-0.36.3 streamlit-1.32.2 tiktoken-0.6.0 types-requests-2.31.0.6 types-urllib3-1.26.25.14 typing-extensions-4.9.0 typing-inspect-0.9.0 unstructured-0.12.6 unstructured-client-0.18.0 urllib3-1.26.18 uvicorn-0.29.0 uvloop-0.19.0 watchdog-4.0.0 watchfiles-0.21.0 websockets-12.0 wrapt-1.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "b09c5f081db14fa29d58cc8701eee715"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain pypdf rapidocr-onnxruntime streamlit unstructured pdf2image pdfminer.six pikepdf pillow_heif langchain_experimental\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrCy5YsfCk22",
        "outputId": "ae1a5c98-3337-457c-813a-7b1c8ce8e468"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add API keys and other environmental variables"
      ],
      "metadata": {
        "id": "8dMY__NjCtZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Replace 'your_file.json' with the path to your actual JSON file\n",
        "file_path = '/content/drive/MyDrive/OpenAI_API/Keys.json'\n",
        "\n",
        "# Read the JSON file\n",
        "with open(file_path, 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract the value associated with the key 'k'\n",
        "# Replace 'k' with your actual key name if different\n",
        "OPENAI_API_KEY = data.get('OPENAI_API_KEY', None)  # Returns None if 'OPENAI_API_KEY' is not found\n",
        "LANGSMITH_API_KEY = data.get('LANGSMITH', None)  # Returns None if 'OPENAI_API_KEY' is not found\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DjLluZ92CnpM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To better secure for API keys set them inside of the session manualy"
      ],
      "metadata": {
        "id": "A28AaRuBvPuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "#print(f'Enter the OPEN AI API key')\n",
        "#OPENAI_API_KEY = getpass()"
      ],
      "metadata": {
        "id": "CE4r4kQgC8tY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(f'Enter the LANGCHAIN API key')\n",
        "#LANGSMITH_API_KEY = getpass()"
      ],
      "metadata": {
        "id": "WvyjXZrdDJbA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#OpenAI API key\n",
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY#data.get('OPENAI_API_KEY', None)\n",
        "\n",
        "#Setup LangSmith to trace development\n",
        "from langsmith import Client\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = 'RAG_CHAT'\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = LANGSMITH_API_KEY\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
      ],
      "metadata": {
        "id": "X1RQS91LDQ68"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating ChatBot**"
      ],
      "metadata": {
        "id": "JTluVg8tDeEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define models\n",
        "#Full list of models https://platform.openai.com/docs/models/overview\n",
        "GPT4 = 'gpt-4-0125-preview'\n",
        "GPT3 = 'gpt-3.5-turbo-0125'"
      ],
      "metadata": {
        "id": "uuOruuKbDaCL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import\n",
        "#Import ChatOpenAI class\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "# Import ChatMessageHistory class that will store our chat history.\n",
        "# Import chat prompt templates classes and Message placeholders classes\n",
        "from langchain.memory import ChatMessageHistory\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "#Define stop words for our chatbot\n",
        "stop_words = [\"exit\", \"quit\", \"stop\"]\n",
        "\n",
        "#Define chat history\n",
        "chat_history = ChatMessageHistory()\n",
        "\n",
        "#Adding messages to the chat history (optional)\n",
        "# Add a user message to the chat history\n",
        "chat_history.add_user_message(\"What day ChatGPT was launched\")\n",
        "# Add an AI response message to the chat history\n",
        "chat_history.add_ai_message(\"ChatGPT was launched at November 30, 2022\")\n",
        "# Add a user message to the chat history\n",
        "chat_history.add_user_message(\"Was it successful aunch?\")\n",
        "\n",
        "#Define LLM\n",
        "\n",
        "Chat = ChatOpenAI(model = GPT3)\n",
        "\n",
        "# Create a ChatPromptTemplate using messages\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        # Define a system message as a tuple\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
        "        ),\n",
        "        # Add a placeholder for the chat messages\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "#Define the chain\n",
        "Chat_chain = prompt | Chat\n",
        "\n",
        "#Use RunnableWithMessageHistory as a wrapper to manage message history\n",
        "Chain_with_message_history = RunnableWithMessageHistory(\n",
        "    Chat_chain,\n",
        "    #define access to chat history\n",
        "    lambda session_id : chat_history,\n",
        "    input_messages_key=\"messages\",\n",
        "    history_messages_key=\"chat_history\"\n",
        ")\n",
        "\n",
        "# Perform chat runs\n",
        "print(\"Starting the chat...\")\n",
        "while True:\n",
        "    question = input(\"User: \")\n",
        "\n",
        "    # Check if the user input matches a stop word\n",
        "    if question.lower() in stop_words:\n",
        "        print(\"Exiting the chat...\")\n",
        "        break\n",
        "\n",
        "    # Add a user message to the chat history\n",
        "    chat_history.add_user_message(question)\n",
        "\n",
        "    #Generate AI response\n",
        "    ai_response = Chain_with_message_history.invoke({\"messages\": chat_history.messages}, {\"configurable\": {\"session_id\": chat_history }})#chat_history}})\n",
        "\n",
        "    # Add an AI response message to the chat history\n",
        "    chat_history.add_ai_message(ai_response.content)\n",
        "\n",
        "    #Display AI answer\n",
        "    print(f\"AI: {ai_response.content}\")\n",
        "\n",
        "    ##user_messages:\n",
        "    ## What is the day today?\n",
        "    ## What is you knowledge cut-off date?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk9Pod91DNHv",
        "outputId": "212a9b38-c00c-44f8-b309-f6b661d6b6d7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting the chat...\n",
            "User: What is the day today?\n",
            "AI: I'm an AI assistant and I don't have real-time information. Could you please confirm today's date for me?\n",
            "User: What is the day today?\n",
            "AI: Today is Sunday.\n",
            "User: What is you knowledge cut-off date?\n",
            "AI: My responses are based on the information available up to the present time. I don't have a specific knowledge cut-off date, but I provide information based on the latest data and knowledge available. If you have any specific questions or need up-to-date information, feel free to ask!\n",
            "User: exit\n",
            "Exiting the chat...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating ChatBot with RAG**"
      ],
      "metadata": {
        "id": "lZugIE9Ucxku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll create the chatbot to save some time watching all Youtube video presentation but instead directly asking the questions we are interested. I'm very interested about this new Time Series package AutoGluon released by Amazon, and I want to build a ChatBot to address my quations.\n",
        "The name of the video we'll use is [Caner Turkmen, Oleksandr Shchur: AutoGluon - AutoML for Tabular, Multimodal and Time Series Data](https://www.youtube.com/watch?v=Lwu15m5mmbs&t=181s)"
      ],
      "metadata": {
        "id": "HGWYJowOhfhE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required libraries to load data from Youtube"
      ],
      "metadata": {
        "id": "-VdtgAY4i-oG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d54sIur8gDM0",
        "outputId": "c04ebbd2-1918-47dd-c5a9-12538ccdfc38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.2.2)\n",
            "Installing collected packages: pytube, youtube-transcript-api\n",
            "Successfully installed pytube-15.0.0 youtube-transcript-api-0.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data from Youtube"
      ],
      "metadata": {
        "id": "CIk90jXYjNGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import YoutubeLoader\n",
        "\n",
        "# Use the YoutubeLoader to load and parse the transcript of a YouTube video\n",
        "loader = YoutubeLoader.from_youtube_url(\"https://www.youtube.com/watch?v=Lwu15m5mmbs&t=181s\", add_video_info=True)\n",
        "video = loader.load()\n",
        "video"
      ],
      "metadata": {
        "id": "Z-qj-gLVf-Mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "334b3717-2f09-49e8-cd22-7e5396953d62"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"hey hey everyone mic check is is everything okay like with the voice all right great and thanks Antonia for the introduction that was about half the talk so uh we'll we'll focus the rest of our time into like the nitty-gritty of the library so um first of all welcome everyone to our session on autoglo on autoglo on is our automl library that provides a variety of data modalities for you to work with uh myself John R and Alexander will be presenting the session my name is Jenner I've I work at AWS I'm a senior applied scientist I've been with the company for about four years now and in the general data science space for about a decade uh Alexander my colleague is also an applied scientist at AWS and together uh he got his PhD recently from the Technical University of Munich and together we work on the forecasting time series uh features within the General Auto go on framework so um let's start so I'm going to start with uh basically describing ml in a nutshell and try to frame the problem of automl there but like this is ml in a nutshell before chat CPT basically but like what what you might encounter in any ml problem or in the general let's say workflow of a data scientist is you have data right so that data can come in multiple modalities that might be images Text tabular data and time series data perhaps and you have a specific task that you want to address for example if it's tabular data you might be interested in regression classification if it's images could be image classification Etc and finally what you really want on the third pillar here is you want a machine that can make predictions like a test time on data it has never seen before and hopefully those predictions are accurate predictions um they they are basically usable they they arrive in like good time Etc and in like that uh second pillar that does not at all do any justice to the amount of work that is required is the real work of like most some of the work of a data scientist which is pre-processing that data trying out different models trying out different approaches for solving that task and finally you know selecting one model or one approach that can give you the best performance at test time right and automl in a nutshell is trying to take that second pillar and trying to automate as much of that away as possible so as to make the lives of data scientists much easier and get to the most accurate models with like maybe as little as three lines of code and in in the least amount of human involvement as possible Right and auto gluon does just that auto gluon is an automl Library framework that it aims primarily to democratize machine learning so as to empower the next millions of data scientists and it what it does for you is in a nutshell it builds accurate models for a variety of tasks in like with image data Text data time series data or tabular data with as little as three lines of code hiding away all of that complexity that we just talked about in the second pillar and it is open source it's available on GitHub we'll share the links and it is also very easy to install it's available on Pi Pi so you can just pip install auto glue on and get started with auto glue Auto glue on is used in over 200 Amazon projects internally so it is it Powers bits and pieces of our external facing AI Services those you might have heard of include like for example sagemaker if you've ever used that it also is used internally by amazon.com teams and a variety of tasks for example in supply chain tasks Etc and not only that it is also adopted externally by 50 companies at least that we know of brand names including ones like Intel Nvidia IBM and autoglo on on a variety of tasks that it was designed to work on it is the state of the art in terms of performance or like performance per training Time Performance for inference time and it was featured as the opening keynote of the automl conference in 2022. so I will first start this talk by describing what it can do for tabular data and trying to give you a sense of like uh like how easy it is to use and what it does under the hood and then Alexander will take over for like the more interesting stuff that includes images text and time series and time series the one that's really closest to our hearts and to be able to do that let me first start by introducing uh the problem the problem is well it's the first problem that you see in data science school like if you ever went there like on day one right so it's like you have a table of data and it includes some columns those columns are your features and particularly if you're interested in supervised learning that that's most of what we're interested in ought to go on you have one particular column that is of interest that column is your label so to speak and if that label is real valued you're trying to solve an aggression problem trying to predict that column in terms of the others and if that feature is uh categorical you're trying to solve a classification problem and auto gluon we promise that can do that in like as little as two or three lines of code trying to solve that uh tabular problem would be as easy as just calling the tabular predictor object and that's really the only class name that you have to know about if you're trying to address tabular problems you give it the name of the label column that is once you know you want it to expect from the data you're going to give it you point it to the data you tell it vaguely what to do like focus on quality here like try to get me the best most accurate models possible you specify the time limit we're going to go into the details later and you and really it just takes an hour to train the best it can the best classification of regression models depending on the task it can for you and you can then take that predictor object you can save it and then like you call it back and you can use the predict method on it at test time so um and you know how do we do that how do we hide away all of the complexity of like building models selecting models optimizing models and giving the best performance and to be able to describe that I should first really um go into a bit of History here so how these models or how Auto gluon came to be the the real inspiration of autoglone is actually um maybe like if you've ever competed in machine learning competitions like on platforms like kaggle if you did that five years ago maybe it was easy to call whatever was the state-of-the-art classification model for example back then for example your random Forest random forests were pretty popular this might be more than five years ago or like XG boost and you could have gotten like a really good let's say ranking and that was like the good old days of capital but really soon after that what happened in uh like the kaggler machine learning competition space is people started building these automated pipelines that just generate like hosts of plethora of features um train like you know just swaths of models like different models and then just build those models on top of one another stack them on top of each other into these huge monstrous architectures and um get the best for performance this was actually also the case that in the Netflix uh competition if anyone remembers that so in the Netflix competition Netflix went out and said like can somebody please point us to a good algorithm for uh doing recommendations and the best thing that came back was like something that the Netflix Engineers I said okay we accept that that is performing very well but like this is a monster like if we went out and tried to implement this like it would take us ages and auto glue on what it tries to do is it tries to replicate as much of that competition winning logic but like in a completely automated manner in a completely like hiding away all of the complexity of both training such architectures and also deploying them in test time with as like with just a very simple very narrow very concise interface for its users and uh that philosophy also reflects in the competition results of course so in many uh you know competitions where uh like Auto glue on is tried and just like with either no or very little tuning it can come to very competitive rankings uh and as Alexander will talk about not only in tabular tasks but also in in multimodal tasks and not only that in academic benchmarks as well this is The automl Benchmark it's a very comprehensive um comparison of different automl Frameworks so other Frameworks that are trying to solve this problem of like get the best model with minimal human intervention in the best possible time it categorically outperforms all of the other Frameworks some of which are commercially available it does this not only on like on average but uh I could say categorically across different tasks so binary classification multi-class classification and regression problems and also for different time windows so when all of the Frameworks are given one hour to train also for when all of the Frameworks are given four hours to train Etc and that the paper is available in archive and um like I would recommend it as like also a good like introductory reading to the automl space if you're interested in like an academic view of things um and to be able to describe uh how that happens I already alluded to like competition beating monsters but allow me to go into a bit more detail at an intuitive level on how that happens so if you went to any automl conference even like last year or mention the word automl to people working in this space their uh perception of that concept would be equivalent almost to this uh thing called the cash problem there in parentheses which is like the combined algorithm selection and Hyper parameter tuning model uh problem which basically just says let's say you're trying to solve regression you have these very different models let's say those in scikit-learn one of them is like linear regression another one is like support Vector regression etc etc and what you want to do is given a specific amount of time you want to go to each one model you want to tune their hyper parameters maybe you uh sort of search the best regularization hyper parameter in one you try to search for if you're doing a neural network regression for example you try to search for the best neural network architecture in one and try to come up with the one single best model that wins overall that you expect it to generalize the best at prediction time autoglo on does that but it also does a few things on top so first it has some let's say uh built-in data pre-processing data preprocessing that you might find in some of those like competitive machine learning pipelines it has emphasis on Modern deep learning techniques so like it always will include some sort of deep learning even if it's working on tabular or time series data to get like squeeze out the best performance for you from your data and it can like all completely hide away the complexity of doing that right so you don't have to um like even if you have a GPU it will sort of try and find it find it and use it for you it has um lots and lots of tricks and optimizations that go into like how to select models and what type of problems and like Which models to prefer it has a lot of presets as we will talk about so you can sort of maybe not being at all an expert user you can nudge it in the direction of like this is the type of models that I want to use and this is the type of performance that I want to get out of this library but most importantly there is number two and like I ask myself why we put it there and number two is uh ensembling why a multi-layer stacking so it's that idea of building monsters like with models upon models upon models instead of relying on the single best model can we come up with the best Ensemble of models that won't really penalizes all that much at test time in terms of like how long it takes to predict but it really gives a huge performance boost in terms of accuracy and like the task at hand and the key idea of assembling may be going a bit into that is that simply many are better than few right so if you have two models and those two models make their own mistakes so to speak so they have their own inductive biases and they look at the same data set but they fail in different ways those two models or three models can come like they can vote within each other so to speak and come to a consensus and that consensus uh will uh usually like all you know in some cases always be better than uh the uh any one individual model even if those models are worse in isolation and when you're trying to solve this cash problem you're trying to select the best algorithm that the thing is that you have gone and spent all that compute in trying to find that best model right so you've you've done your linear regression in our previous example you've done your support Vector regression you've done your neural network so why throw all of those away at test time instead of just like taking some of them and packaging them and ensembling them into a new model and that that's really what uh the key idea of ensembling is and in multi-layer stack ensembling it's the the idea is that you uh get your input data you try to um not there it appears you you have trained all of the different models your linear regressor your support Vector regressor your your neural network Etc and uh what you do on top is you get your original data think a data frame you concatenate you you join in the the predictions of the layer 1 models and you use that new data to train a new cohort of models however of course the key trick here to to enable like better generalization is that this new data is out of full this is like a new data set that was held out from uh training the first let's say chord like the the first layer of models and this this is really like all there is to it this is what at least Auto Glow on tabular Taps heavily into instead of like very very involved hyper parameter optimization algorithms things like Bayesian optimization uh let's say multi-fidelity methods things like that if you've ever heard that are more like you know classical let's say autonomo and of course for all of that to work you need a good model zoo and auto glue on offers a good variety so like all of the things that you can come across at and kaggle maybe uh we we try to put them in there and try to maintain the complexity of making those things play nice together for you including things like XC boost like GBM cat pushed neural network models that are based on pytorch uh that are all in there and that that will hopefully come and start working together when you do the PIP install and we try to hide away all of the complexity behind this very intuitive API where now I can go into more detail you just tell it what you're trying to do you and label class essentially does that you say okay give me a predictor object this is really one of the few objects that you need to know about if you're using the library and you're trying to predict a column named class you point it to the data set that data set might be a string like a file name a URL can be a pandas data frame can be a variety of things and you tell it presets so presets is um you're trying to nudge the library so we offer like a bunch of these presets now you're trying to nudge the library into selecting um like a strategy really so best quality means you want the the most accurate models no matter what uh but you could have said like for example fast inference So you you're trying to tell it to okay you know maybe sort of I I have a little bit of give in terms of uh accuracy but uh please give me something that will work fast at test time and the time limit uh is like how much you wanted to train here it's like one hour in terms of seconds you're saying okay I want you to do whatever you do in the the time frame of an hour and that's really all there is to it it will train a host of different models that were like we work on all the time to pre-select like the the roster of models that will work best for you and hopefully give you something that works like state of the art performance okay now is the time I hand over to Alex for the rest of the talk thanks a lot thank you um thank you chairman um so as we have seen with the tabular predictor we can do extremely well in different tablet prediction problems like classification regression but of course in many practical applications the data that we have does not really like perfectly fit into this format of just a table that has numbers and categories in it very often we have to work with images or maybe text data or even like in some quite challenged applications we have the combinations of all these data modalities together where you can have both potentially multiple images various text fields in addition to the table data we have seen before like new numbers and categories to make this a bit more specific we can have a look at the Pathfinder computation that took place in kaggle where the goal was basically to predict when different when pets will get adopted so for each pet you had a picture and so an image also some tabular metadata described in this image and the goal was to predict some score which tells us how quickly this bet is going to get adopted and this would help the shelters to better help pets find their new homes and here you see we have the combination of all these different data types in a prediction problem um as a like a bit more of a you know like practical minded example we can think of some online store where you have a huge catalog of products and there each product also has all of these different features we have multiple photos of the product we have a text field which is a description and the title and also have different numerical and categorical attributes like price uh color maybe model Etc and one question you might be interested in asking is whether this product is actually a duplicate of something else we have in the data set so let's say when a new seller comes to the platform tries to sell a new product um you want to say is this what is what they're trying to sell something we already have in our catalog or is it um something new that we should like list as a new item in the category and of course these are just some examples I'm sure in applications that you're working on you have encountered some other problems where you have to deal with this multimodal data where all the different data modalities are present and argon can also help to solve problems like this and again to work with this data we again have to somehow coerce it into a table of format but now the stable you see is a bit more General than what we have that what China has showed us before where now we also besides the numerical and categorical data types we also have some other data types like images and text for example for images we can have paths to images area that you're stored on your computer and for text it's just strings that we have there for some other applications like if you have to do object detection you want to find different objects and images you can also have bounding boxes as a column here in the data frame or if you want to do name an entity recognition text you can have this named entities also there's another attribute and once you can convert the data into this format you can again throw it into outer glow on and get the best possible prediction in a limited amount of time and for this um there is a multi-model module of outer glowing where we have another object called multimodal predictor which takes care of various tasks associated with such multimodal data like images text Etc and as you see the API here is very similar to the table predictor just a few lines of code fit in predicting and this solves the problem and and under the hood what happens here is we wrap various Foundation models coming from libraries like Tim mm detection clip hug and face Transformers and combine their predictions so we do multi-modal Fusion of these various models we train special test specific hats that allow us to fine-tune this model specifically to your task so say even if you don't have much experience working with such complex models yourself you can just put your data in this format throw the multimodal predictor edit and it will take care of all these complex fine-tuning jobs for you we can also use these models mentioned in here in a different way and combine them with the tabular predictor and so let's say if you have some classification problem where you have to classify some images one thing you can do is you can use these Foundation models to get embeddance which is basically converting each image into some array with something dimensionality and then with this these embeddings that we have obtained from the models we can again put them into Auto Glow and tabular and train the tabular and Sample we have seen before so essentially what this does it converts the multimodal problem into a tableau problem where we can use all the classical tools for Tableau Data and then just uses the tablet predictor to solve the problems that you have um in terms of support for various problem times that we have for multimodal data these are as I already mentioned the classical things like classification and regression but now for combinations of images stacks and tabular data and but also some more interesting things that are more specific to um this multimodal data so one such example is named entity recognition where let's say you have various documents with text and you might be interested in finding some enter this mentioned in there let's say there is some company name you want to see whether this company name is mentioned in various text documents and this way multiple predicted with the problem type and ER for name entity recognition can do this for you and we can also do problems that are like more image specific such as object detection and where you want to find various objects located in an image so let's say for like self-driving you might want to be able to you might want to detect pedestrians you might want to protect detect other cars or stop signs or things like that and this is covered by the object detection problem type and finally what I mentioned as an example in the beginning with this like object matching and this is what we call here as multimodal matching and there the question is where you have different objects represented by images text tabular Data you want to answer the the question are these two objects the same so given a bunch of images text descriptions and table data for one object and for the other we want to ask is this the same object or is it something else um or other different so this way the multimodal prediction will just give you some score that tells you how similar the two stains are um um in terms of their specifics as to how this whole thing works and like I said we use various Foundation models provided by these libraries and depending on the type of the data so depending on the modality whether it's images text or just tabular data we pass it to the respective models they can process this data and these models are some things like I don't know efficient net or resnet if you know like for a computer vision applications Transformer models um or even multimodal models that takes multiple inputs such as clip and then once um for the multimodal projector once we pass them into these models we can then do fine tuning so depending on the application let's say if you want to do classification it passes data into the models and then trains an additional layer on top which helps you classify based on the inputs coming from these models so essentially taking care of all this complexity of managing various models coming from different libraries with the simple API of the multi-model predictor um the final thing that I want to talk about today is a um is another application supported by other glowing which is time series forecasting and this is again quite different from table of data quite different from multimodal and Aragon can help you deal with this as well and so time series is essentially some set of measurements to make at regular intervals let's say you're some Energy company and you want to um you want to you can measure like the energy consumption of some household every hour and you can plot it like here you just use this curve so for every hour we have the measurement and they're usually interested in asking the question what will happen in the future how would this develop over time for an energy company it might be interesting for example to Planet capacities for electricity let's if say if you if you expect a big spike in consumption you need to make sure that you have the available capacity in your network this also doesn't have to be in electricity consumption can be for example demand forecasting in a retail where you have to stock your inventory to make sure that if there are more sales coming you have enough and enough of the units in stock to fulfill this demand and these all these different questions of where you have some quantities changing over time you can frame them as time series forecasting problems um the way we are usually interested in solving them as practice is but not we're just giving you a single prediction for every time step into the future so I don't want to say like the energy consumption tomorrow is going to be 150 because it doesn't that's not all we need to make these uh like decisions in the end Downstream what we really care about is the range of possible outcomes so maybe we want the model to tell us okay there is a 90 chance that the demand for this product tomorrow is going to be 150 and 170 units and this way we're actually able to plan our inventory where we know okay we are kind of expect to be within these reasonable Within These bounds and this is what we use for the downstream predictions and mathematically this corresponds to predicting the quantiles um of the distribution which essentially means the model just gives you some number and saying so here we see the 10 quantile the model says there's 10 chance that the maybe demand for this product is going to be below uh this number in here and you also predict that 90 quantile sense of there's a 90 chance the demand is going to be below uh this number in here and in total this is kind of the range that we can expect to see for our time series and and this is exactly the kind of problem that outer glow on time series is designed to do is to generate such probabilistic forecasts a four time series data another important aspect um when doing time series forecasting is that we don't usually only have that one time series that we are trying to predict so let's say we don't only have the sales for one product that we are trying to predict we actually have a lot of other additional information um for example we can have some other things that change over time let's say we know that maybe we know if we'll have some promotions on different items we know if there will be some holidays or weekends and as you can imagine this can all affect say your sales or um other properties of the time series and this can all be combined together to generate the most accurate forecasts and so in this figure you see on top there original times here that we are trying to predict we have some other time series that we only know in the past which can for example be demand for a related product in a different category that we have observed historically and there can also be some other time Verizon coverage which is maybe like an indicator whether we have a promotion on this item or not and that we also because we control it we also know what its value going to be in the future and all of these we can combine together and describing them as covariates and finally um when working with these time series data sets we usually don't just have a single time series you want to predict but we have many time series that we are trying to predict simultaneously so let's say for um demand forecasting we don't just want to predict the demand for a single product we want to predict demand for all the products in our catalog which can be thousands of Time series each corresponding to in separate to a separate product and here for each time series we can also associate some metadata like name of the products category price or maybe some other features that help us generate the forecast for example if we know that some products are all sold in the same location we might want to give the model the capability to generate similar forecasts to the products sold in the same store that is located in the same state um to feed the air we can fit such all these all these types of data into um to Outer glow on by combining them again into a data frame which we now call A Time series data frame where the idea is to stack all these various time series into one big table where for each role we have some indicator for the time series so here you see we have the indicator for product a and we also have one column describing the timestamps telling us when um telling us when the times UFL was recorded we have the Target Time series which is the maybe the demand for the product that we have at each specific day and we can also have some additional covariates in this case we have the weekend which allows the model to determine whether um um which a lot of the models uses information in the production as well and once we pack all of our data into this time series data frame um we can just call autoblow on the time series predictor in this case and it will generate a probabilistic forecast for us as you see the API is also um quite simple but compared to what we have seen before we have we just have to specify the prediction lens down how many steps into the future we want to predict so let's say if I have Daily Time series data this way I will tell the predictor please generate the forecast for the next 30 days for each time series in my data set and we call fit we call predict as usual and now predictions will contain the probabilistic forecasts for all the time series in my original training data so you see what's a bit different in Time series world is that we don't really have this like training validation split we'll try and test split we only have training data and then when we generate the predictions this contains the future this contain the future values of the time series um that we had in the training set and internally um the time series module combines various the forecasting approaches starting from simple statistical models like arima that essentially capture simple patterns in the data like seasonality Trends um maybe some other aggressive structure and these are usually very fast to fit but um might not be super but not be super accurate so to compensate for that auto loan also fits deep learning models from the gluing TF Library such as DPR and these are usually take a bit longer to train but can give you more accurate predictions and also do quite well when combining these various and static features we have seen before and of course there we can use the integration with Auto Glow and tabular to use the different tabular models like CAD boost and light GBM and in use as usual in the autoblown way we do a sampling of all these models to generate the best possible model that will give you the most accurate forecast I want to quickly jump over a few things here that are not really specific to the time series model um but what I want to show you is that essentially in outer glowing even though the basic API is very simple where you only need a few lines of code to Define your problem and generate predictions there's also lots of room for configuration and you can really tailor it to your specific application and you can tell to your specific application and make sure that it generates the best result for you if you have something that is very non-standard and it's not covered by the presets or the default so for example for time series you can say which quantile levels you want to predict you can say which metric should be used to measure your forecast so you can say say with this choice you would say I care really care about the uncertainty of my forecasts with some other choices you could say I only care about having a single accurate prediction for each time step which is like a time and which is um which is like a point forecast and also for when trading the models you can as usual use the preset in all these different modules but you can also use outer go on as like a very simple wrapper about around other libraries so let's say if you wanted to train statistical models deep learning models tree based models for forecasting usually you would have to implement the train validation strategy yourself some evaluation pipeline various data pre-processing by hand but this way with auto blown you can also just say I only want to train these models and other go on with automatically train these models evaluate them for you and and basically simplify your work as maybe some more advanced user who doesn't need the presets but wants to do something custom themselves um yeah and since we're closing time so there are also some other modules offering other functionality in Aragon that I haven't covered here which is more like additional functionality that you might be interested in using and yeah and and finally just to say like if you are interested in learning more about how to go on please visit the website we have lots of information in there we have the documentation and we have various tutorials quick start guides installation instructions and since it's an open source package you can visit on GitHub and you can also of course also of course welcome to contribute uh if you would like to add some new features or tell us about something that you found in the package and you can just install it with Pip and try it out thank you [Applause] thank you very much for this great presentation so we have quite some questions um on slido the first one would be stakeholders often explicitly ask for explainability to what extent and how does autoglone enable that so I awesome so we I know we had at one point some explainability features in the tabular module it's not like a primary focus of the library so we're it's more of a accuracy type of like that's what we optimized for I guess um but like one could always uh as Alexander just talked about like by sort of focusing the selection of models to only those that are very interpretable Etc one could sort of nudge the library towards um that direction however um we do not have like out of the box support for explainability and for example in Time series or um multimodal problems as far as how would you deploy a model after training so this is one of the cases where other modules of Aragon can be helpful for example autoglone Cloud allows you to both train the models in the cloud and also deploy them in there so you would just get an endpoint where you can send your data and get the predictions back um this is I guess the recommended way of doing this but you can of course also because it's open source you can deploy it on your own infrastructure and we also offer Docker containers on AWS that you can use for that or you can you know since it's an open source Library just install it yourself and use it in your own infrastructure cool what work does autoglone do in the feature pre-processing processing stage for example fill the missing values and such um this is specific for every model so this is like one of the ideas of auto loan is to generate predictions that are as diverse as possible across different models to make sure we get the good ones so in for example for tabular data this is all model specific so for each model we try different pre-processing if you want you can override those defaults uh but by default we are trying to try out many different strategies to make sure we get the right thing in there cool comparing to Pi carrot as also an automl platform what is the what are the pros and cons of this one um I'm not really familiar with my character unfortunately uh yeah um does the time series forecasting also work for relative days IG day one day two Etc um yeah I mean so the generate the forecast contains predictions from multiple time steps so if you say you only I mean I guess you can just generate the prediction lens to be let's say if you have to need to have forecast for up to 10 days you can either use one predictor and then only look at the forecast for a single day or you can train multiple predictors with different prediction lengths this is the standard way okay I'll say uh are the sub models extractable for further tuning um yes but since we mostly rely on samples it might not be like you might not be only interested in a single sub-module um but in principle this can be done yes cool I mentioned the focus on deep learning methods how many samples it needs for robust solution and in a seasonality based time series for example so I guess based on some benchmarking that we did ourselves for a Time series for the smaller time series usually deep learning models don't give you that much of an advantage over the simple ones so I think in that setting if you have little data you would mostly use the statistical models for forecasting and but you know autogome automatically determine whether like which one should be used but what I want to mention like we don't really support cold start forecasting so if you only know half the time series for one or two time steps this is one case where autoglone is not there yet to support it but this is something we consider adding in the future um how do you tackle back test overfitting for the time series case um I I think that's a really good question so one thing we do is like we enable multi-window back testing so like you can actually that's one of the configuration parameters that you could have put into the time series predictor object the same like uh during fit you you say like I I actually want you to not only focus on one window and try to predict that and model select based on that do that on multiple windows by iteratively fitting models going forward okay is it possible to do hierarchical forecasting with auto glue on not not yet okay why why don't you use profit for Time series so that that's another part of I I think autoglo on history there was a time that we did included in the model zoo over our experience with profit has been that like the difficulty of maintaining it especially during inference and deploying it to like cross-platform it's just like the um the difficulty of doing that doesn't justify the accuracy benefits we get similar benefits from other statistical models Fair is it possible to parameterize a forecasting Horizon for the feature lack creation feature or lack creation um yes so as I mentioned here you can configure all the models that we have in the forecasting Zoo so you can provide those type of parameters and say what is how exactly you should they should be configured which lags they should use so I'd like to to to be clear this is like a model specific choice right so not all models are designed to work with features even so okay so there are many more questions actually um I bet you can approach um those two and ask the questions afterwards so again thank you very much for a great presentation thank you [Applause]\", metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'})]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split the video transcript. into chunks\n"
      ],
      "metadata": {
        "id": "pwZmZitRjUfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import text splitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Create an instance of RecursiveCharacterTextSplitter with custom chunk size and overlap\n",
        "chunk_size = 300  # Adjust the chunk size as needed\n",
        "chunk_overlap = 0  # Set the overlap between chunks\n",
        "\n",
        "#Initiate splitter with desired parameters\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "\n",
        "# Split the document into chunks using the RecursiveCharacterTextSplitter\n",
        "splits = splitter.split_documents(video)\n",
        "\n",
        "# Print the number of splits in the doc\n",
        "print(f'Number of text splits in the document is: {len(splits)}')\n",
        "\n",
        "# Print each split and a separator for readability\n",
        "for split in splits:\n",
        "    print(split)\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJXeyGl6jchZ",
        "outputId": "23b2fd8a-f1af-425d-a11d-a9a8c2cc5329"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of text splits in the document is: 134\n",
            "page_content=\"hey hey everyone mic check is is everything okay like with the voice all right great and thanks Antonia for the introduction that was about half the talk so uh we'll we'll focus the rest of our time into like the nitty-gritty of the library so um first of all welcome everyone to our session on\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"autoglo on autoglo on is our automl library that provides a variety of data modalities for you to work with uh myself John R and Alexander will be presenting the session my name is Jenner I've I work at AWS I'm a senior applied scientist I've been with the company for about four years now and in\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='the general data science space for about a decade uh Alexander my colleague is also an applied scientist at AWS and together uh he got his PhD recently from the Technical University of Munich and together we work on the forecasting time series uh features within the General Auto go on framework so' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"um let's start so I'm going to start with uh basically describing ml in a nutshell and try to frame the problem of automl there but like this is ml in a nutshell before chat CPT basically but like what what you might encounter in any ml problem or in the general let's say workflow of a data\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"scientist is you have data right so that data can come in multiple modalities that might be images Text tabular data and time series data perhaps and you have a specific task that you want to address for example if it's tabular data you might be interested in regression classification if it's\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='images could be image classification Etc and finally what you really want on the third pillar here is you want a machine that can make predictions like a test time on data it has never seen before and hopefully those predictions are accurate predictions um they they are basically usable they they' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='arrive in like good time Etc and in like that uh second pillar that does not at all do any justice to the amount of work that is required is the real work of like most some of the work of a data scientist which is pre-processing that data trying out different models trying out different approaches' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='for solving that task and finally you know selecting one model or one approach that can give you the best performance at test time right and automl in a nutshell is trying to take that second pillar and trying to automate as much of that away as possible so as to make the lives of data scientists' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='much easier and get to the most accurate models with like maybe as little as three lines of code and in in the least amount of human involvement as possible Right and auto gluon does just that auto gluon is an automl Library framework that it aims primarily to democratize machine learning so as to' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='empower the next millions of data scientists and it what it does for you is in a nutshell it builds accurate models for a variety of tasks in like with image data Text data time series data or tabular data with as little as three lines of code hiding away all of that complexity that we just talked' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"about in the second pillar and it is open source it's available on GitHub we'll share the links and it is also very easy to install it's available on Pi Pi so you can just pip install auto glue on and get started with auto glue Auto glue on is used in over 200 Amazon projects internally so it is it\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"Powers bits and pieces of our external facing AI Services those you might have heard of include like for example sagemaker if you've ever used that it also is used internally by amazon.com teams and a variety of tasks for example in supply chain tasks Etc and not only that it is also adopted\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='externally by 50 companies at least that we know of brand names including ones like Intel Nvidia IBM and autoglo on on a variety of tasks that it was designed to work on it is the state of the art in terms of performance or like performance per training Time Performance for inference time and it' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='was featured as the opening keynote of the automl conference in 2022. so I will first start this talk by describing what it can do for tabular data and trying to give you a sense of like uh like how easy it is to use and what it does under the hood and then Alexander will take over for like the' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"more interesting stuff that includes images text and time series and time series the one that's really closest to our hearts and to be able to do that let me first start by introducing uh the problem the problem is well it's the first problem that you see in data science school like if you ever\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"went there like on day one right so it's like you have a table of data and it includes some columns those columns are your features and particularly if you're interested in supervised learning that that's most of what we're interested in ought to go on you have one particular column that is of\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"interest that column is your label so to speak and if that label is real valued you're trying to solve an aggression problem trying to predict that column in terms of the others and if that feature is uh categorical you're trying to solve a classification problem and auto gluon we promise that can\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"do that in like as little as two or three lines of code trying to solve that uh tabular problem would be as easy as just calling the tabular predictor object and that's really the only class name that you have to know about if you're trying to address tabular problems you give it the name of the\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"label column that is once you know you want it to expect from the data you're going to give it you point it to the data you tell it vaguely what to do like focus on quality here like try to get me the best most accurate models possible you specify the time limit we're going to go into the details\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='later and you and really it just takes an hour to train the best it can the best classification of regression models depending on the task it can for you and you can then take that predictor object you can save it and then like you call it back and you can use the predict method on it at test time' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='so um and you know how do we do that how do we hide away all of the complexity of like building models selecting models optimizing models and giving the best performance and to be able to describe that I should first really um go into a bit of History here so how these models or how Auto gluon came' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"to be the the real inspiration of autoglone is actually um maybe like if you've ever competed in machine learning competitions like on platforms like kaggle if you did that five years ago maybe it was easy to call whatever was the state-of-the-art classification model for example back then for\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"example your random Forest random forests were pretty popular this might be more than five years ago or like XG boost and you could have gotten like a really good let's say ranking and that was like the good old days of capital but really soon after that what happened in uh like the kaggler machine\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='learning competition space is people started building these automated pipelines that just generate like hosts of plethora of features um train like you know just swaths of models like different models and then just build those models on top of one another stack them on top of each other into these' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='huge monstrous architectures and um get the best for performance this was actually also the case that in the Netflix uh competition if anyone remembers that so in the Netflix competition Netflix went out and said like can somebody please point us to a good algorithm for uh doing recommendations and' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='the best thing that came back was like something that the Netflix Engineers I said okay we accept that that is performing very well but like this is a monster like if we went out and tried to implement this like it would take us ages and auto glue on what it tries to do is it tries to replicate as' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='much of that competition winning logic but like in a completely automated manner in a completely like hiding away all of the complexity of both training such architectures and also deploying them in test time with as like with just a very simple very narrow very concise interface for its users and' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='uh that philosophy also reflects in the competition results of course so in many uh you know competitions where uh like Auto glue on is tried and just like with either no or very little tuning it can come to very competitive rankings uh and as Alexander will talk about not only in tabular tasks but' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"also in in multimodal tasks and not only that in academic benchmarks as well this is The automl Benchmark it's a very comprehensive um comparison of different automl Frameworks so other Frameworks that are trying to solve this problem of like get the best model with minimal human intervention in\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='the best possible time it categorically outperforms all of the other Frameworks some of which are commercially available it does this not only on like on average but uh I could say categorically across different tasks so binary classification multi-class classification and regression problems and' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='also for different time windows so when all of the Frameworks are given one hour to train also for when all of the Frameworks are given four hours to train Etc and that the paper is available in archive and um like I would recommend it as like also a good like introductory reading to the automl' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"space if you're interested in like an academic view of things um and to be able to describe uh how that happens I already alluded to like competition beating monsters but allow me to go into a bit more detail at an intuitive level on how that happens so if you went to any automl conference even\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='like last year or mention the word automl to people working in this space their uh perception of that concept would be equivalent almost to this uh thing called the cash problem there in parentheses which is like the combined algorithm selection and Hyper parameter tuning model uh problem which' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"basically just says let's say you're trying to solve regression you have these very different models let's say those in scikit-learn one of them is like linear regression another one is like support Vector regression etc etc and what you want to do is given a specific amount of time you want to go\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"to each one model you want to tune their hyper parameters maybe you uh sort of search the best regularization hyper parameter in one you try to search for if you're doing a neural network regression for example you try to search for the best neural network architecture in one and try to come up\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"with the one single best model that wins overall that you expect it to generalize the best at prediction time autoglo on does that but it also does a few things on top so first it has some let's say uh built-in data pre-processing data preprocessing that you might find in some of those like\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"competitive machine learning pipelines it has emphasis on Modern deep learning techniques so like it always will include some sort of deep learning even if it's working on tabular or time series data to get like squeeze out the best performance for you from your data and it can like all completely\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"hide away the complexity of doing that right so you don't have to um like even if you have a GPU it will sort of try and find it find it and use it for you it has um lots and lots of tricks and optimizations that go into like how to select models and what type of problems and like Which models to\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='prefer it has a lot of presets as we will talk about so you can sort of maybe not being at all an expert user you can nudge it in the direction of like this is the type of models that I want to use and this is the type of performance that I want to get out of this library but most importantly there' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"is number two and like I ask myself why we put it there and number two is uh ensembling why a multi-layer stacking so it's that idea of building monsters like with models upon models upon models instead of relying on the single best model can we come up with the best Ensemble of models that won't\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='really penalizes all that much at test time in terms of like how long it takes to predict but it really gives a huge performance boost in terms of accuracy and like the task at hand and the key idea of assembling may be going a bit into that is that simply many are better than few right so if you' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='have two models and those two models make their own mistakes so to speak so they have their own inductive biases and they look at the same data set but they fail in different ways those two models or three models can come like they can vote within each other so to speak and come to a consensus and' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"that consensus uh will uh usually like all you know in some cases always be better than uh the uh any one individual model even if those models are worse in isolation and when you're trying to solve this cash problem you're trying to select the best algorithm that the thing is that you have gone\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"and spent all that compute in trying to find that best model right so you've you've done your linear regression in our previous example you've done your support Vector regression you've done your neural network so why throw all of those away at test time instead of just like taking some of them and\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"packaging them and ensembling them into a new model and that that's really what uh the key idea of ensembling is and in multi-layer stack ensembling it's the the idea is that you uh get your input data you try to um not there it appears you you have trained all of the different models your linear\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='regressor your support Vector regressor your your neural network Etc and uh what you do on top is you get your original data think a data frame you concatenate you you join in the the predictions of the layer 1 models and you use that new data to train a new cohort of models however of course the' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"key trick here to to enable like better generalization is that this new data is out of full this is like a new data set that was held out from uh training the first let's say chord like the the first layer of models and this this is really like all there is to it this is what at least Auto Glow on\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"tabular Taps heavily into instead of like very very involved hyper parameter optimization algorithms things like Bayesian optimization uh let's say multi-fidelity methods things like that if you've ever heard that are more like you know classical let's say autonomo and of course for all of that to\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='work you need a good model zoo and auto glue on offers a good variety so like all of the things that you can come across at and kaggle maybe uh we we try to put them in there and try to maintain the complexity of making those things play nice together for you including things like XC boost like GBM' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='cat pushed neural network models that are based on pytorch uh that are all in there and that that will hopefully come and start working together when you do the PIP install and we try to hide away all of the complexity behind this very intuitive API where now I can go into more detail you just tell' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"it what you're trying to do you and label class essentially does that you say okay give me a predictor object this is really one of the few objects that you need to know about if you're using the library and you're trying to predict a column named class you point it to the data set that data set\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"might be a string like a file name a URL can be a pandas data frame can be a variety of things and you tell it presets so presets is um you're trying to nudge the library so we offer like a bunch of these presets now you're trying to nudge the library into selecting um like a strategy really so\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"best quality means you want the the most accurate models no matter what uh but you could have said like for example fast inference So you you're trying to tell it to okay you know maybe sort of I I have a little bit of give in terms of uh accuracy but uh please give me something that will work fast\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"at test time and the time limit uh is like how much you wanted to train here it's like one hour in terms of seconds you're saying okay I want you to do whatever you do in the the time frame of an hour and that's really all there is to it it will train a host of different models that were like we\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='work on all the time to pre-select like the the roster of models that will work best for you and hopefully give you something that works like state of the art performance okay now is the time I hand over to Alex for the rest of the talk thanks a lot thank you um thank you chairman um so as we have' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='seen with the tabular predictor we can do extremely well in different tablet prediction problems like classification regression but of course in many practical applications the data that we have does not really like perfectly fit into this format of just a table that has numbers and categories in' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='it very often we have to work with images or maybe text data or even like in some quite challenged applications we have the combinations of all these data modalities together where you can have both potentially multiple images various text fields in addition to the table data we have seen before' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='like new numbers and categories to make this a bit more specific we can have a look at the Pathfinder computation that took place in kaggle where the goal was basically to predict when different when pets will get adopted so for each pet you had a picture and so an image also some tabular metadata' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='described in this image and the goal was to predict some score which tells us how quickly this bet is going to get adopted and this would help the shelters to better help pets find their new homes and here you see we have the combination of all these different data types in a prediction problem um' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='as a like a bit more of a you know like practical minded example we can think of some online store where you have a huge catalog of products and there each product also has all of these different features we have multiple photos of the product we have a text field which is a description and the' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"title and also have different numerical and categorical attributes like price uh color maybe model Etc and one question you might be interested in asking is whether this product is actually a duplicate of something else we have in the data set so let's say when a new seller comes to the platform\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"tries to sell a new product um you want to say is this what is what they're trying to sell something we already have in our catalog or is it um something new that we should like list as a new item in the category and of course these are just some examples I'm sure in applications that you're\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='working on you have encountered some other problems where you have to deal with this multimodal data where all the different data modalities are present and argon can also help to solve problems like this and again to work with this data we again have to somehow coerce it into a table of format but' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"now the stable you see is a bit more General than what we have that what China has showed us before where now we also besides the numerical and categorical data types we also have some other data types like images and text for example for images we can have paths to images area that you're stored\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"on your computer and for text it's just strings that we have there for some other applications like if you have to do object detection you want to find different objects and images you can also have bounding boxes as a column here in the data frame or if you want to do name an entity recognition\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"text you can have this named entities also there's another attribute and once you can convert the data into this format you can again throw it into outer glow on and get the best possible prediction in a limited amount of time and for this um there is a multi-model module of outer glowing where we\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='have another object called multimodal predictor which takes care of various tasks associated with such multimodal data like images text Etc and as you see the API here is very similar to the table predictor just a few lines of code fit in predicting and this solves the problem and and under the' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='hood what happens here is we wrap various Foundation models coming from libraries like Tim mm detection clip hug and face Transformers and combine their predictions so we do multi-modal Fusion of these various models we train special test specific hats that allow us to fine-tune this model' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"specifically to your task so say even if you don't have much experience working with such complex models yourself you can just put your data in this format throw the multimodal predictor edit and it will take care of all these complex fine-tuning jobs for you we can also use these models mentioned\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"in here in a different way and combine them with the tabular predictor and so let's say if you have some classification problem where you have to classify some images one thing you can do is you can use these Foundation models to get embeddance which is basically converting each image into some\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='array with something dimensionality and then with this these embeddings that we have obtained from the models we can again put them into Auto Glow and tabular and train the tabular and Sample we have seen before so essentially what this does it converts the multimodal problem into a tableau problem' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='where we can use all the classical tools for Tableau Data and then just uses the tablet predictor to solve the problems that you have um in terms of support for various problem times that we have for multimodal data these are as I already mentioned the classical things like classification and' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"regression but now for combinations of images stacks and tabular data and but also some more interesting things that are more specific to um this multimodal data so one such example is named entity recognition where let's say you have various documents with text and you might be interested in\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"finding some enter this mentioned in there let's say there is some company name you want to see whether this company name is mentioned in various text documents and this way multiple predicted with the problem type and ER for name entity recognition can do this for you and we can also do problems\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"that are like more image specific such as object detection and where you want to find various objects located in an image so let's say for like self-driving you might want to be able to you might want to detect pedestrians you might want to protect detect other cars or stop signs or things like\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='that and this is covered by the object detection problem type and finally what I mentioned as an example in the beginning with this like object matching and this is what we call here as multimodal matching and there the question is where you have different objects represented by images text tabular' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='Data you want to answer the the question are these two objects the same so given a bunch of images text descriptions and table data for one object and for the other we want to ask is this the same object or is it something else um or other different so this way the multimodal prediction will just' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"give you some score that tells you how similar the two stains are um um in terms of their specifics as to how this whole thing works and like I said we use various Foundation models provided by these libraries and depending on the type of the data so depending on the modality whether it's images\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"text or just tabular data we pass it to the respective models they can process this data and these models are some things like I don't know efficient net or resnet if you know like for a computer vision applications Transformer models um or even multimodal models that takes multiple inputs such as\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"clip and then once um for the multimodal projector once we pass them into these models we can then do fine tuning so depending on the application let's say if you want to do classification it passes data into the models and then trains an additional layer on top which helps you classify based on\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='the inputs coming from these models so essentially taking care of all this complexity of managing various models coming from different libraries with the simple API of the multi-model predictor um the final thing that I want to talk about today is a um is another application supported by other' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"glowing which is time series forecasting and this is again quite different from table of data quite different from multimodal and Aragon can help you deal with this as well and so time series is essentially some set of measurements to make at regular intervals let's say you're some Energy company\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"and you want to um you want to you can measure like the energy consumption of some household every hour and you can plot it like here you just use this curve so for every hour we have the measurement and they're usually interested in asking the question what will happen in the future how would this\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"develop over time for an energy company it might be interesting for example to Planet capacities for electricity let's if say if you if you expect a big spike in consumption you need to make sure that you have the available capacity in your network this also doesn't have to be in electricity\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='consumption can be for example demand forecasting in a retail where you have to stock your inventory to make sure that if there are more sales coming you have enough and enough of the units in stock to fulfill this demand and these all these different questions of where you have some quantities' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"changing over time you can frame them as time series forecasting problems um the way we are usually interested in solving them as practice is but not we're just giving you a single prediction for every time step into the future so I don't want to say like the energy consumption tomorrow is going to\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"be 150 because it doesn't that's not all we need to make these uh like decisions in the end Downstream what we really care about is the range of possible outcomes so maybe we want the model to tell us okay there is a 90 chance that the demand for this product tomorrow is going to be 150 and 170\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"units and this way we're actually able to plan our inventory where we know okay we are kind of expect to be within these reasonable Within These bounds and this is what we use for the downstream predictions and mathematically this corresponds to predicting the quantiles um of the distribution which\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"essentially means the model just gives you some number and saying so here we see the 10 quantile the model says there's 10 chance that the maybe demand for this product is going to be below uh this number in here and you also predict that 90 quantile sense of there's a 90 chance the demand is going\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='to be below uh this number in here and in total this is kind of the range that we can expect to see for our time series and and this is exactly the kind of problem that outer glow on time series is designed to do is to generate such probabilistic forecasts a four time series data another important' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"aspect um when doing time series forecasting is that we don't usually only have that one time series that we are trying to predict so let's say we don't only have the sales for one product that we are trying to predict we actually have a lot of other additional information um for example we can\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"have some other things that change over time let's say we know that maybe we know if we'll have some promotions on different items we know if there will be some holidays or weekends and as you can imagine this can all affect say your sales or um other properties of the time series and this can all\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='be combined together to generate the most accurate forecasts and so in this figure you see on top there original times here that we are trying to predict we have some other time series that we only know in the past which can for example be demand for a related product in a different category that' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='we have observed historically and there can also be some other time Verizon coverage which is maybe like an indicator whether we have a promotion on this item or not and that we also because we control it we also know what its value going to be in the future and all of these we can combine together' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"and describing them as covariates and finally um when working with these time series data sets we usually don't just have a single time series you want to predict but we have many time series that we are trying to predict simultaneously so let's say for um demand forecasting we don't just want to\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='predict the demand for a single product we want to predict demand for all the products in our catalog which can be thousands of Time series each corresponding to in separate to a separate product and here for each time series we can also associate some metadata like name of the products category' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='price or maybe some other features that help us generate the forecast for example if we know that some products are all sold in the same location we might want to give the model the capability to generate similar forecasts to the products sold in the same store that is located in the same state um' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='to feed the air we can fit such all these all these types of data into um to Outer glow on by combining them again into a data frame which we now call A Time series data frame where the idea is to stack all these various time series into one big table where for each role we have some indicator for' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='the time series so here you see we have the indicator for product a and we also have one column describing the timestamps telling us when um telling us when the times UFL was recorded we have the Target Time series which is the maybe the demand for the product that we have at each specific day and' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='we can also have some additional covariates in this case we have the weekend which allows the model to determine whether um um which a lot of the models uses information in the production as well and once we pack all of our data into this time series data frame um we can just call autoblow on the' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"time series predictor in this case and it will generate a probabilistic forecast for us as you see the API is also um quite simple but compared to what we have seen before we have we just have to specify the prediction lens down how many steps into the future we want to predict so let's say if I\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='have Daily Time series data this way I will tell the predictor please generate the forecast for the next 30 days for each time series in my data set and we call fit we call predict as usual and now predictions will contain the probabilistic forecasts for all the time series in my original training' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"data so you see what's a bit different in Time series world is that we don't really have this like training validation split we'll try and test split we only have training data and then when we generate the predictions this contains the future this contain the future values of the time series um\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='that we had in the training set and internally um the time series module combines various the forecasting approaches starting from simple statistical models like arima that essentially capture simple patterns in the data like seasonality Trends um maybe some other aggressive structure and these are' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='usually very fast to fit but um might not be super but not be super accurate so to compensate for that auto loan also fits deep learning models from the gluing TF Library such as DPR and these are usually take a bit longer to train but can give you more accurate predictions and also do quite well' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='when combining these various and static features we have seen before and of course there we can use the integration with Auto Glow and tabular to use the different tabular models like CAD boost and light GBM and in use as usual in the autoblown way we do a sampling of all these models to generate' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='the best possible model that will give you the most accurate forecast I want to quickly jump over a few things here that are not really specific to the time series model um but what I want to show you is that essentially in outer glowing even though the basic API is very simple where you only need' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"a few lines of code to Define your problem and generate predictions there's also lots of room for configuration and you can really tailor it to your specific application and you can tell to your specific application and make sure that it generates the best result for you if you have something that\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"is very non-standard and it's not covered by the presets or the default so for example for time series you can say which quantile levels you want to predict you can say which metric should be used to measure your forecast so you can say say with this choice you would say I care really care about\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='the uncertainty of my forecasts with some other choices you could say I only care about having a single accurate prediction for each time step which is like a time and which is um which is like a point forecast and also for when trading the models you can as usual use the preset in all these' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"different modules but you can also use outer go on as like a very simple wrapper about around other libraries so let's say if you wanted to train statistical models deep learning models tree based models for forecasting usually you would have to implement the train validation strategy yourself some\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"evaluation pipeline various data pre-processing by hand but this way with auto blown you can also just say I only want to train these models and other go on with automatically train these models evaluate them for you and and basically simplify your work as maybe some more advanced user who doesn't\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"need the presets but wants to do something custom themselves um yeah and since we're closing time so there are also some other modules offering other functionality in Aragon that I haven't covered here which is more like additional functionality that you might be interested in using and yeah and\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"and finally just to say like if you are interested in learning more about how to go on please visit the website we have lots of information in there we have the documentation and we have various tutorials quick start guides installation instructions and since it's an open source package you can\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='visit on GitHub and you can also of course also of course welcome to contribute uh if you would like to add some new features or tell us about something that you found in the package and you can just install it with Pip and try it out thank you [Applause] thank you very much for this great' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"presentation so we have quite some questions um on slido the first one would be stakeholders often explicitly ask for explainability to what extent and how does autoglone enable that so I awesome so we I know we had at one point some explainability features in the tabular module it's not like a\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"primary focus of the library so we're it's more of a accuracy type of like that's what we optimized for I guess um but like one could always uh as Alexander just talked about like by sort of focusing the selection of models to only those that are very interpretable Etc one could sort of nudge the\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='library towards um that direction however um we do not have like out of the box support for explainability and for example in Time series or um multimodal problems as far as how would you deploy a model after training so this is one of the cases where other modules of Aragon can be helpful for' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"example autoglone Cloud allows you to both train the models in the cloud and also deploy them in there so you would just get an endpoint where you can send your data and get the predictions back um this is I guess the recommended way of doing this but you can of course also because it's open source\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"you can deploy it on your own infrastructure and we also offer Docker containers on AWS that you can use for that or you can you know since it's an open source Library just install it yourself and use it in your own infrastructure cool what work does autoglone do in the feature pre-processing\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='processing stage for example fill the missing values and such um this is specific for every model so this is like one of the ideas of auto loan is to generate predictions that are as diverse as possible across different models to make sure we get the good ones so in for example for tabular data' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='this is all model specific so for each model we try different pre-processing if you want you can override those defaults uh but by default we are trying to try out many different strategies to make sure we get the right thing in there cool comparing to Pi carrot as also an automl platform what is' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"the what are the pros and cons of this one um I'm not really familiar with my character unfortunately uh yeah um does the time series forecasting also work for relative days IG day one day two Etc um yeah I mean so the generate the forecast contains predictions from multiple time steps so if you\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"say you only I mean I guess you can just generate the prediction lens to be let's say if you have to need to have forecast for up to 10 days you can either use one predictor and then only look at the forecast for a single day or you can train multiple predictors with different prediction lengths\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"this is the standard way okay I'll say uh are the sub models extractable for further tuning um yes but since we mostly rely on samples it might not be like you might not be only interested in a single sub-module um but in principle this can be done yes cool I mentioned the focus on deep learning\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"methods how many samples it needs for robust solution and in a seasonality based time series for example so I guess based on some benchmarking that we did ourselves for a Time series for the smaller time series usually deep learning models don't give you that much of an advantage over the simple\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"ones so I think in that setting if you have little data you would mostly use the statistical models for forecasting and but you know autogome automatically determine whether like which one should be used but what I want to mention like we don't really support cold start forecasting so if you only\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"know half the time series for one or two time steps this is one case where autoglone is not there yet to support it but this is something we consider adding in the future um how do you tackle back test overfitting for the time series case um I I think that's a really good question so one thing we\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"do is like we enable multi-window back testing so like you can actually that's one of the configuration parameters that you could have put into the time series predictor object the same like uh during fit you you say like I I actually want you to not only focus on one window and try to predict that\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"and model select based on that do that on multiple windows by iteratively fitting models going forward okay is it possible to do hierarchical forecasting with auto glue on not not yet okay why why don't you use profit for Time series so that that's another part of I I think autoglo on history there\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"was a time that we did included in the model zoo over our experience with profit has been that like the difficulty of maintaining it especially during inference and deploying it to like cross-platform it's just like the um the difficulty of doing that doesn't justify the accuracy benefits we get\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='similar benefits from other statistical models Fair is it possible to parameterize a forecasting Horizon for the feature lack creation feature or lack creation um yes so as I mentioned here you can configure all the models that we have in the forecasting Zoo so you can provide those type of' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content=\"parameters and say what is how exactly you should they should be configured which lags they should use so I'd like to to to be clear this is like a model specific choice right so not all models are designed to work with features even so okay so there are many more questions actually um I bet you\" metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n",
            "page_content='can approach um those two and ask the questions afterwards so again thank you very much for a great presentation thank you [Applause]' metadata={'source': 'Lwu15m5mmbs', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'description': 'Unknown', 'view_count': 921, 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'publish_date': '2023-06-20 00:00:00', 'length': 2602, 'author': 'PyData'}\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create embeddings"
      ],
      "metadata": {
        "id": "9iLTH6h-jlbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import vectorstore database and embeddings model\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Embeddings model\n",
        "# Chose embeddings model\n",
        "# Selected model is well described in https://openai.com/blog/new-embedding-models-and-api-updates\n",
        "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "#Define vector DB. Run this line of code only once.\n",
        "#If accidently did more delete DB\n",
        "vector_db = Chroma.from_documents(documents=splits, embedding=embeddings_model)\n",
        "\n",
        "#Define retriever\n",
        "retriever = vector_db.as_retriever()\n",
        "\n"
      ],
      "metadata": {
        "id": "x6c0Wk0QgY61"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code to delete db. (if needed)\n",
        "\n",
        "# Delete the collection\n",
        "#vector_db.delete_collection()\n",
        "#print(\"Collection deleted successfully.\")"
      ],
      "metadata": {
        "id": "N5IW2-LUkmjB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing model"
      ],
      "metadata": {
        "id": "ZY0047CqeCEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define question\n",
        "question = 'What are the main features of AutoGluon for Time Series data?'\n",
        "\n",
        "#Fetch 3 documents from vector store related to question\n",
        "vector_db.similarity_search_with_score(question, k=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM9pZg9SeBJE",
        "outputId": "445ceb28-6fc0-44e0-b90a-04a350c7f205"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(page_content='much easier and get to the most accurate models with like maybe as little as three lines of code and in in the least amount of human involvement as possible Right and auto gluon does just that auto gluon is an automl Library framework that it aims primarily to democratize machine learning so as to', metadata={'author': 'PyData', 'description': 'Unknown', 'length': 2602, 'publish_date': '2023-06-20 00:00:00', 'source': 'Lwu15m5mmbs', 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'view_count': 921}),\n",
              "  0.3640797436237335),\n",
              " (Document(page_content=\"glowing which is time series forecasting and this is again quite different from table of data quite different from multimodal and Aragon can help you deal with this as well and so time series is essentially some set of measurements to make at regular intervals let's say you're some Energy company\", metadata={'author': 'PyData', 'description': 'Unknown', 'length': 2602, 'publish_date': '2023-06-20 00:00:00', 'source': 'Lwu15m5mmbs', 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'view_count': 921}),\n",
              "  0.37029528617858887),\n",
              " (Document(page_content=\"and model select based on that do that on multiple windows by iteratively fitting models going forward okay is it possible to do hierarchical forecasting with auto glue on not not yet okay why why don't you use profit for Time series so that that's another part of I I think autoglo on history there\", metadata={'author': 'PyData', 'description': 'Unknown', 'length': 2602, 'publish_date': '2023-06-20 00:00:00', 'source': 'Lwu15m5mmbs', 'thumbnail_url': 'https://i.ytimg.com/vi/Lwu15m5mmbs/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgYyhOMA8=&rs=AOn4CLBQMQ6d2UBD3hwRitYgFYqgmOkZ1w', 'title': 'Caner Turkmen, Oleksandr Shchur:  AutoGluon - AutoML for Tabular, Multimodal and Time Series Data', 'view_count': 921}),\n",
              "  0.39383283257484436)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, the reply from the human delivered presentation is definetly not really good. Let's try to do the same but using the paper [AutoGluon–TimeSeries:\n",
        "AutoML for Probabilistic Time Series Forecasting](https://arxiv.org/abs/2308.05566)"
      ],
      "metadata": {
        "id": "cNhU350LnPjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First we delete the vector database\n",
        "#Code to delete db. (if needed)\n",
        "\n",
        "# Delete the collection\n",
        "#vector_db.delete_collection()\n",
        "#print(\"Collection deleted successfully.\")"
      ],
      "metadata": {
        "id": "5nlxxHjqnt_I"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import pdf loader.\n",
        "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
        "\n",
        "#Define loader\n",
        "loader_pdf = UnstructuredPDFLoader(\"/content/drive/My Drive/OpenAI_API/AutoGluon–TimeSeries.pdf\")\n",
        "#Load an article\n",
        "article_pdf = loader_pdf.load()\n",
        "\n",
        "#Print doc to check it out\n",
        "#print(article_pdf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrCp0VMkc0_1",
        "outputId": "e7caad6e-c0e1-4ec1-bb81-966bec9c368f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import text splitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Create an instance of RecursiveCharacterTextSplitter with custom chunk size and overlap\n",
        "chunk_size = 750  # Adjust the chunk size as needed\n",
        "chunk_overlap = 0  # Set the overlap between chunks\n",
        "\n",
        "#Initiate splitter with desired parameters\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "\n",
        "# Split the document into chunks using the RecursiveCharacterTextSplitter\n",
        "splits = splitter.split_documents(article_pdf)\n",
        "\n",
        "# Print the number of splits in the doc\n",
        "print(f'Number of text splits in the document is: {len(splits)}')\n",
        "\n",
        "# Print each split and a separator for readability\n",
        "#for split in splits:\n",
        "#    print(split)\n",
        "#    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oBlr-2SoL8W",
        "outputId": "f5c2e166-edb0-488a-862a-427f39591f7c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of text splits in the document is: 123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import vectorstore database and embeddings model\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Embeddings model\n",
        "embeddings_model = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
        "\n",
        "#Define vector DB. Run this line of code only once.\n",
        "#If accidently did more delete DB\n",
        "\n",
        "vector_db = Chroma.from_documents(documents=splits, embedding=embeddings_model)\n",
        "\n",
        "#Define retriever\n",
        "retriever = vector_db.as_retriever()\n",
        "\n"
      ],
      "metadata": {
        "id": "RXwrmIPKolB9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define question\n",
        "question = 'What are the main features of AutoGluon for Time Series data?'\n",
        "\n",
        "#Fetch 3 documents from vector store related to question\n",
        "vector_db.similarity_search_with_score(question, k=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MInyTuO5oq9T",
        "outputId": "0ca12035-0c96-4fe5-a847-04a885905573"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(page_content='AutoGluon–TimeSeries enables users to generate accurate forecasts in a few lines of code. This democratizes machine learning, lowering the barrier to entry to forecasting for non-experts. At the same time, AutoGluon–TimeSeries can be used by experienced users to design highly accurate forecasting pipelines. More accurate forecasts can directly translate to real-world impact in various domains. For example, forecasting renewable energy generation is a crucial component of smart grid management (Tripathy and Prusty, 2021); accurately predicting demand leads to more efficient inventory management and increased revenue (Makridakis et al., 2022).', metadata={'source': '/content/drive/My Drive/OpenAI_API/AutoGluon–TimeSeries.pdf'}),\n",
              "  0.18131937086582184),\n",
              " (Document(page_content='Abstract We introduce AutoGluon–TimeSeries—an open-source AutoML library for probabilistic time series forecasting.1 Focused on ease of use and robustness, AutoGluon–TimeSeries enables users to generate accurate point and quantile forecasts with just 3 lines of Python code. Built on the design philosophy of AutoGluon, AutoGluon–TimeSeries leverages ensembles of diverse forecasting models to deliver high accuracy within a short training time. AutoGluon– TimeSeries combines both conventional statistical models, machine-learning based forecasting approaches, and ensembling techniques. In our evaluation on 29 benchmark datasets, AutoGluon–TimeSeries demonstrates strong empirical performance, outperforming a range of forecasting methods in', metadata={'source': '/content/drive/My Drive/OpenAI_API/AutoGluon–TimeSeries.pdf'}),\n",
              "  0.1899060308933258),\n",
              " (Document(page_content='In this work, we introduced AutoGluon–TimeSeries, a powerful and user-friendly open-source AutoML library for probabilistic time series forecasting. By combining statistical models and deep learning forecasting approaches with ensembling techniques, AutoGluon–TimeSeries is able to achieve strong empirical results on a range of benchmark datasets. With the ability to generate accurate point and quantile forecasts with just 3 lines of Python code, this framework is poised to make time series forecasting more accessible and efficient for a wide range of users.\\n\\n8 Broader Impact Statement', metadata={'source': '/content/drive/My Drive/OpenAI_API/AutoGluon–TimeSeries.pdf'}),\n",
              "  0.20043803751468658)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test the responses for the qustion using data from Vector Database**"
      ],
      "metadata": {
        "id": "V-_L3R24o6Kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "# Prompt\n",
        "template = \"\"\"Answer the question based on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "#Define rag_prompt from template\n",
        "rag_prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "#Print the promt to check it everything is ok\n",
        "#rag_prompt\n",
        "\n",
        "#Define LLM\n",
        "RAG_llm = ChatOpenAI(model=GPT3)\n",
        "\n",
        "#Define Chain\n",
        "RAG_chain = rag_prompt | RAG_llm\n",
        "\n",
        "#Assign docs\n",
        "docs = vector_db.similarity_search(question, k=3)\n",
        "\n",
        "#Chain to answer question based on defined docs\n",
        "RAG_chain.invoke({\"context\":docs,\"question\": question})\n",
        "\n",
        "# Create the Retrieval-Augmented Generation (RAG) chain with dynamic retrieval\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "rag_chain = (\n",
        "    # Define the input variables for the chain\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    # Pipe the input through the RAG prompt template\n",
        "    | rag_prompt\n",
        "    # Pass the formatted prompt to the language model (LLM)\n",
        "    | RAG_llm\n",
        "    # Parse the LLM's output using the StrOutputParser\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "#Invoke the chain\n",
        "\n",
        "rag_chain.invoke(\"What are the main features of AutoGluon for Time Series data?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "cYzzJW6Uou0k",
        "outputId": "09255777-dd62-4cc9-848c-88c132376de6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The main features of AutoGluon for Time Series data include:\\n1. Ability to generate accurate forecasts with just a few lines of Python code\\n2. Combines statistical models, machine-learning based forecasting approaches, and ensembling techniques\\n3. Can generate both point and probabilistic forecasts\\n4. Supports both static and time-varying covariates\\n5. Designed for ease of use and robustness\\n6. Demonstrates strong empirical performance on benchmark datasets'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Build RAG BOT chain prompt template**"
      ],
      "metadata": {
        "id": "CLZaGeKlpkD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_community.vectorstores import Chroma  # Assuming this is the type of your vector_db\n",
        "\n",
        "# Initialize the OpenAI Chat model\n",
        "chat = ChatOpenAI(\n",
        "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "    model='gpt-3.5-turbo'\n",
        ")\n",
        "\n",
        "\n",
        "# Function to augment the prompt with contextual information from your vector database\n",
        "def augment_prompt(query: str, vector_db):\n",
        "    results = vector_db.similarity_search(query, k=3)\n",
        "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
        "    augmented_prompt = f\"\"\"Using the contexts below, answer the query:\n",
        "\n",
        "    Context:\n",
        "    {source_knowledge}\n",
        "\n",
        "    Query: {query}\"\"\"\n",
        "    return augmented_prompt\n",
        "\n",
        "# Define stop words for our chatbot\n",
        "stop_words = [\"exit\", \"quit\", \"stop\"]\n",
        "\n",
        "# Initialize the chat history\n",
        "chat_history = ChatMessageHistory()\n",
        "\n",
        "# Define the initial system message and add it to the messages\n",
        "initial_system_message = SystemMessage(content=\"You are a helpful assistant. Answer the questions based on the provided context.\")\n",
        "#messages = initial_system_message\n",
        "\n",
        "# Define the chat prompt with augmented context outside the loop\n",
        "rag_bot_prompt = ChatPromptTemplate.from_messages([\n",
        "    initial_system_message,\n",
        "    MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    # The context-rich prompt from user query will be dynamically added later in the loop\n",
        "])\n",
        "\n",
        "# Create the RAG LLM chain by piping the RAG prompt to the LLM\n",
        "rag_bot_chain = rag_bot_prompt | chat\n",
        "# Setup the chat chain with message history\n",
        "rag_chain_with_message_history = RunnableWithMessageHistory(\n",
        "        runnable=rag_bot_chain,  # Chain the prompt template with the ChatOpenAI instance\n",
        "        get_session_history=lambda session_id: chat_history,\n",
        "        input_messages_key=\"messages\",\n",
        "        history_messages_key=\"chat_history\"\n",
        "    )\n",
        "\n",
        "# Setup the interactive chat structure\n",
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in stop_words:\n",
        "        print(\"Exiting the chat...\")\n",
        "        break\n",
        "    chat_history.add_user_message(user_input)\n",
        "\n",
        "    # Generate the augmented prompt with the new user query\n",
        "    augmented_prompt = augment_prompt(user_input, vector_db)\n",
        "     # Treat augmented prompt as an additional message for context.\n",
        "     #This actually prioritize the information in Vector database over the data from internet\n",
        "    chat_history.add_message(augmented_prompt)\n",
        "\n",
        "    # Generate the AI response with the augmented context\n",
        "    ai_response = rag_chain_with_message_history.invoke({\"messages\": chat_history.messages}, {\"configurable\": {\"session_id\": chat_history}})\n",
        "\n",
        "    # Add the AI response to the chat history and display it\n",
        "    chat_history.add_ai_message(ai_response.content)\n",
        "    print(f\"AI: {ai_response.content}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbUDsC7_uOv7",
        "outputId": "609fd6e6-0eb2-4e4c-ad1e-b56abe47767c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: What are the main features of AutoGluon for Time Series data?\n",
            "AI: The main features of AutoGluon for Time Series data include:\n",
            "1. Ease of use: Users can generate accurate forecasts with just a few lines of Python code, making forecasting more accessible to non-experts.\n",
            "2. Robustness: AutoGluon combines conventional statistical models, machine-learning based forecasting approaches, and ensembling techniques to deliver high accuracy in a short training time.\n",
            "3. Performance: AutoGluon demonstrates strong empirical performance on a variety of benchmark datasets, outperforming a range of forecasting methods.\n",
            "4. Accessibility: By leveraging ensembles of diverse forecasting models, AutoGluon enables both non-experts and experienced users to design highly accurate forecasting pipelines efficiently.\n",
            "User: What models does AutoGluon use to forecast Time Series data?\n",
            "AI: AutoGluon uses a combination of models to forecast Time Series data, including:\n",
            "1. Conventional statistical models\n",
            "2. Machine-learning based forecasting approaches\n",
            "3. Ensembling techniques\n",
            "\n",
            "By leveraging this diverse set of models, AutoGluon is able to deliver high accuracy forecasts within a short training time, making it a powerful tool for time series forecasting.\n",
            "User: Are there any requirements for Time Series data to run the AutoGluon for forecasting?\n",
            "AI: There are no specific requirements mentioned in the provided contexts for Time Series data to run AutoGluon for forecasting. AutoGluon–TimeSeries is designed to be a user-friendly, open-source AutoML library for probabilistic time series forecasting, focusing on ease of use and robustness to enable users to generate accurate forecasts with just a few lines of Python code.\n",
            "User: exit\n",
            "Exiting the chat...\n"
          ]
        }
      ]
    }
  ]
}